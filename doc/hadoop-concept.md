## Overview

> 스파크의 배경이 되는 기술적인 컨셉인 하둡, HDFS, YARN에 대해 간단히 정리한다.

## 01. 빅데이터 아키텍처

빅데이터 아키텍처는 분산시스템에 기반한 계층형 구조로 되어있다. 크게 3개의 주요 계증으로 구성된다.

### 데이터 저장 계층

- HDFS가 위치. 기본적으로 여러 노드에 걸처서 데이터를 분산 저장 및 관리

### 리소스 관리계층

- YARN이 위치
- Resource Manager가 전체 클러스터의 리소를 관리 및 분배
- Node Manager가 개별 서버에서 실제 작업을 실행 및 관리

### 데이터 처리계층

- Spark, Trino, Presto와 같은 처리 엔진들이 존재

## 02. Hadoop

- 기본적인 하둡의 대규모 데이터 프로세싱 방식은 Divide and Conquer 방식이다.
- 핵심은 대규모 문제를 일련의 작업으로 나누고 그 중 많은 부분을 병렬로 실행하는 것이다.


![](../../../../../static/images/hadoop.png)

### **클러스터링**

- 클러스터는 연산이나 프로세싱 함수를 수행하기 위해 함께 작동하는 시스템 모음이다.
- 클러스터 내의 개별 서버를 노드라 한다.
- 클러스터의 대표적인 통신 모델은 마스터-슬레이브 모델이다.
- 마스터-슬레이브 모델은 한 프로세스가 하나 이상의 다른 프로세스를 제어하는 통신 모델이다.

### HDFS

- HDFS는 하둡 분산 파일 시스템(Hadoop Distributed File System)의 약자로, 대규모 데이터 세트를 저장하고 처리하기 위해 설계된 분산 파일 시스템이다.
- HDFS는 기본적으로 하나 이상의 노드에 파일이 분산되어 있는 block 구조로 데이터를 저장한다.
- 모든 블록은 기본적으로 세 개의 복제본을 가진다. 각 복제본은 서로 다른 rack에 있는 노드에 저장됨

**NameNode**

- 파일시스템의 메타데이터를 관리하는 마스터노드
- 파일/디렉토리 구조 정보 저장, 파일명, 권한, 생성 시간 등 파일 속성 관리,블록과 DataNode 간의 매핑 정보 유지, Namespace관리

**DataNode**

- 실제 데이터 블록을 저장하는 워커노드

### HDFS 읽기 및 쓰기 절차

**HDFS 읽기 절차**

1. 클라이언트가 HDFS에 파일 읽기 요청.
2. 네임노드에서 요청된 파일의 블록 복제본이 포함된 데이터노드 목록을 클라이언트에 반환
3. 클라이언트는 데이터노드에 직접 연결하여 블록을 읽는다.

**HDFS 쓰기 절차**

1. 클라이언트가 HDFS에 파일 쓰기 요청.
2. NameNode가 각 블록의 첫번째 복제본을 작성하기 위해 데이터노드 목록을 클라이언트에 반환.
3. 클라이언트가 각 블록의 복제본을을 데이터노드에 작성.
4. 데이터 노드 사이에 복제 파이프라인을 만들고 클라이언트에 알린다.
5. 블록 보고서는 데이터노드에서 네임노드로 정기적으로 전송된다.

---

**_Concept_**

- **Hadoop** : 대용량 데이터의 분산 저장 및 병렬 처리를 위한 오픈소스 프레임워크. 데이터 지역성과 비공유 메모리 아키텍처 등의 기술을 기반으로 한다.
- **Data Locality** : 데이터 지역성. 제너럴한 컨셉은 데이터에 대한 처리작업이 데이터가 있는 노드에 일어나는 것. Hadoop에서 데이터를 처리할 때, 데이터를 이동시키는 대신 계산(MapReduce 작업)을 데이터가 있는 곳으로 이동시켜 네트워크 전송 비용을 줄이고 처리 속도를 향상시키는 개념. 즉, 데이터가 저장된 노드에서 직접 계산을 수행하여 데이터 이동을 최소화하는 것
- **비공유 메모리 아키텍처** : 수평확장. CPU, 메모리, 디스크 등의 리소스를 여러 대의 독립적인 장비(노드)로 분산하여 사용하는 아키텍처로, 각 노드는 독립적으로 동작하며 서로 다른 메모리 공간을 가진다. 이 방식은 확장성이 뛰어나고 내결함성이 높다.ㅏ
- **공유 메모리 아키텍처** : 수직확장. 모든 구성 요소가 동일한 메모리 공간을 공유하는 아키텍처로, 데이터가 한 곳에 집중되어 있어 확장성이 제한적이다.
- **MapReduce** : 대규모 데이터 세트를 처리하기 위한 프로그래밍 모델로, 데이터를 분할하고 병렬로 처리한 후 결과를 결합하는 방식.
- **클러스터** : 연산이나 프로세싱을 위해 여러 대의 노드(컴퓨터)를 연결한 시스템.
- **HDFS** : 하둡 분산 파일 시스템. 대규모 데이터 세트를 저장하고 처리하기 위해 설계된 분산 파일 시스템.
- **Data Node** : HDFS에서 데이터를 저장하는 노드. 실제 파일 데이터를 64MB/128MB 블록 단위로 저장
- **Name Node** : HDFS에서 메타데이터를 관리하는 노드. 파일/디렉토리 구조 정보 저장, 파일명, 권한, 생성 시간 등 파일 속성 관리,블록과 DataNode 간의 매핑 정보 유지, Namespace관리 등의 책임을 가짐

---



## 02. YARN


![](../../../../../static/images/yarn.png)

- 하둡의 리소스 관리 및 작업 스케줄링을 담당하는 컴포넌트. 기본적으로 하둡의 데이터처리를 제어하고 조율하는 역할을 수행.
- YARN의 핵심은 데이터 지역성 최적화. 기본적으로 YARN의 리소스매니저는 어플리케이션이 특정 데이터 파일을 처리하려고 할 때 해당 데이터가 저장된 DataNode와 같은 물리적 노드에 있는 Node Manager에게 컨테이너(자원)을 할당하려 함

### YARN 구성요소

**Resource Manager**

- Resource Manager의 핵심적인 역할은 전체 클러스터의 컴퓨팅 자원을 효율적으로 배분하는 것. 여러 어플리케이션이 동시에 실행될 때, 각각에게 적절한 CPU 및 메모리를 할당해서 충돌 없이 작업할 수 있게끔 조율

**Node Manager**
- NodeManager는 각 워커노드에서 실행되는 일종의 YARN 에이전트. 
- 컨테이너 생명주기 관리, 리소스 모니터링, 로그 관리 등 수행

**Application Master**

- 어플리케이션의 생명주기 전반을 관리하는 마스터 프로세스
- 리소스 요청및 반납. 작업 스케줄링(컨테이너들에서 실행할 작업 관리) . 장애 처리


### YARN의 리소스 할당과정

1. 어플리케이션 제출 : 클라이언트가 Resource Manager에 어플리케이션 제출
1. Application Master 시작 
1. 리소스 요청 : Resource Manager에서 실제 작업 실행을 위한 컨테이너 요청
1. 리소스 할당 : Resource Manager의 Scheduler가 현재 클러스터 상황과 스케줄링 정책을 고려해 요청된 컨테이너들을 할당
1. 컨테이너 시작
1. 어플리케이션 모니터링

---

**_Concept_**

- **YARN** : Yet Another Resource Manager. 분산환경에서 자원관리를 위한 리소스매니저. 핵심 아이디어는 Resource Management, Job Scheduling, Monitoring을 분리된 데몬 프로세스에서 실행하는 것.
- **Resource Manager** : YARN의 마스터 노드로서 전체 클러스터 리소스를 중앙 집중식으로 관리하는 총괄 관리자 
- **Node Manager** :각 워커 노드에서 실행되는 YARN 에이전트로서 컨테이너 생명주기와 리소스를 관리
- **Application Master** : 각 애플리케이션별로 실행되는 전용 관리자로서 해당 애플리케이션의 생명주기를 담당 


---

## Reference

- https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html
