{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "454c5043",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd90ee3e",
   "metadata": {},
   "source": [
    "선형 방정식을 푸는 방법은 크게 두가지가 있다.\n",
    "1. optimial한 값을 찾기 위해선 solve를 이용한다 (단, 해가 존재할 때)\n",
    "   * SVD, 그람슈미트 대각화, QR분해 등을 이용한다.\n",
    "2. regression을 활용한다. (정확한 해가 존재하지 않을때)\n",
    "\n",
    "\n",
    "아래에선 머신러닝 방법인 선형 회귀를 이용하여 선형 방정식의 근사해를 푼다.\n",
    "\n",
    "크게 선형 회귀를 푸는 방법으로 두 가지가 있다\n",
    "1. Ordinary Least Squares (Optimial)\n",
    "2. Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b6aa2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "spark = SparkSession.builder.appName(\"chapter9\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3eab256e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    spark.read.format(\"com.databricks.spark.csv\")\n",
    "    .options(header=\"true\", inferSchema=\"true\")\n",
    "    .load(\"Advertising.csv\", header=\"true\", inferSchema=\"true\")\n",
    "    .select(\"TV\", \"Radio\", \"Newspaper\", \"Sales\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbf98125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+---------+-----+\n",
      "|   TV|Radio|Newspaper|Sales|\n",
      "+-----+-----+---------+-----+\n",
      "|230.1| 37.8|     69.2| 22.1|\n",
      "| 44.5| 39.3|     45.1| 10.4|\n",
      "| 17.2| 45.9|     69.3|  9.3|\n",
      "|151.5| 41.3|     58.5| 18.5|\n",
      "|180.8| 10.8|     58.4| 12.9|\n",
      "+-----+-----+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- TV: double (nullable = true)\n",
      " |-- Radio: double (nullable = true)\n",
      " |-- Newspaper: double (nullable = true)\n",
      " |-- Sales: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5, True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e5f22c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/21 10:42:28 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+------------------+\n",
      "|summary|               TV|             Radio|         Newspaper|             Sales|\n",
      "+-------+-----------------+------------------+------------------+------------------+\n",
      "|  count|              200|               200|               200|               200|\n",
      "|   mean|         147.0425|23.264000000000024|30.553999999999995|14.022500000000003|\n",
      "| stddev|85.85423631490805|14.846809176168728| 21.77862083852283| 5.217456565710477|\n",
      "|    min|              0.7|               0.0|               0.3|               1.6|\n",
      "|    max|            296.4|              49.6|             114.0|              27.0|\n",
      "+-------+-----------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0832c126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummy_supervised(df, indexCol, categoricalCols, continuousCols, labelCol):\n",
    "    indexers = [\n",
    "        StringIndexer(inputCol=c, outputCol=\"{0}_indexed\".format(c))\n",
    "        for c in categoricalCols\n",
    "    ]\n",
    "\n",
    "    # default setting: dropLast=True\n",
    "    encoders = [\n",
    "        OneHotEncoder(\n",
    "            inputCol=indexer.getOutputCol(),\n",
    "            outputCol=\"{0}_encoded\".format(indexer.getOutputCol()),\n",
    "        )\n",
    "        for indexer in indexers\n",
    "    ]\n",
    "\n",
    "    assembler = VectorAssembler(\n",
    "        inputCols=[encoder.getOutputCol() for encoder in encoders] + continuousCols,\n",
    "        outputCol=\"features\",\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline(stages=indexers + encoders + [assembler])\n",
    "\n",
    "    model = pipeline.fit(df)\n",
    "    data = model.transform(df)\n",
    "\n",
    "    data = data.withColumn(\"label\", col(labelCol))\n",
    "\n",
    "    return data.select(indexCol, \"features\", \"label\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0da6322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummy_unsupervised(df, indexCol, categoricalCols, continuousCols):\n",
    "    \"\"\"\n",
    "    Get dummy variables and concat with continuous variables for unsupervised learning.\n",
    "    :param df: the dataframe\n",
    "    :param categoricalCols: the name list of the categorical data\n",
    "    :param continuousCols:  the name list of the numerical data\n",
    "    :return k: feature matrix\n",
    "\n",
    "    :author: Wenqiang Feng\n",
    "    :email:  von198@gmail.com\n",
    "    \"\"\"\n",
    "\n",
    "    indexers = [\n",
    "        StringIndexer(inputCol=c, outputCol=\"{0}_indexed\".format(c))\n",
    "        for c in categoricalCols\n",
    "    ]\n",
    "\n",
    "    # default setting: dropLast=True\n",
    "    encoders = [\n",
    "        OneHotEncoder(\n",
    "            inputCol=indexer.getOutputCol(),\n",
    "            outputCol=\"{0}_encoded\".format(indexer.getOutputCol()),\n",
    "        )\n",
    "        for indexer in indexers\n",
    "    ]\n",
    "\n",
    "    assembler = VectorAssembler(\n",
    "        inputCols=[encoder.getOutputCol() for encoder in encoders] + continuousCols,\n",
    "        outputCol=\"features\",\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline(stages=indexers + encoders + [assembler])\n",
    "\n",
    "    model = pipeline.fit(df)\n",
    "    data = model.transform(df)\n",
    "\n",
    "    return data.select(indexCol, \"features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3198037a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "\n",
    "def transform_data(data):\n",
    "    # toDf() is not a valid method, use toDF() instead (capital DF)\n",
    "    return data.rdd.map(lambda r: [Vectors.dense(r[:-1]), r[-1]]).toDF(\n",
    "        [\"features\", \"label\"]\n",
    "    )\n",
    "\n",
    "\n",
    "data = transform_data(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce65f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "\n",
    "featureIndexer = VectorIndexer(\n",
    "    inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4\n",
    ").fit(data)\n",
    "\n",
    "# data = featureIndexer.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "185d0154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|         features|label|\n",
      "+-----------------+-----+\n",
      "|[230.1,37.8,69.2]| 22.1|\n",
      "| [44.5,39.3,45.1]| 10.4|\n",
      "| [17.2,45.9,69.3]|  9.3|\n",
      "|[151.5,41.3,58.5]| 18.5|\n",
      "|[180.8,10.8,58.4]| 12.9|\n",
      "+-----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66851b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into 60% training and 40% testing\n",
    "(trainingData, testData) = data.randomSplit([0.6, 0.4], seed=12345)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2f5043a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|       features|label|\n",
      "+---------------+-----+\n",
      "| [0.7,39.6,8.7]|  1.6|\n",
      "| [4.1,11.6,5.7]|  3.2|\n",
      "| [5.4,29.9,9.4]|  5.3|\n",
      "|[7.3,28.1,41.4]|  5.5|\n",
      "|[7.8,38.9,50.6]|  6.6|\n",
      "+---------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------------+-----+\n",
      "|        features|label|\n",
      "+----------------+-----+\n",
      "|  [8.4,27.2,2.1]|  5.7|\n",
      "|   [8.6,2.1,1.0]|  4.8|\n",
      "|[17.2,45.9,69.3]|  9.3|\n",
      "|[18.7,12.1,23.4]|  6.7|\n",
      "|[19.4,16.0,22.3]|  6.6|\n",
      "+----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainingData.show(5, True)\n",
    "testData.show(5, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "530490b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor, LinearRegression\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "model = LinearRegression(featuresCol=\"indexedFeatures\", labelCol=\"label\")\n",
    "\n",
    "dt = DecisionTreeRegressor(featuresCol=\"indexedFeatures\", labelCol=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "19066a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/21 11:04:21 WARN Instrumentation: [c6d77a22] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    }
   ],
   "source": [
    "pipeline_lr = Pipeline(stages=[featureIndexer, model])\n",
    "pipeline_dt = Pipeline(stages=[featureIndexer, dt])\n",
    "\n",
    "m_lr = pipeline_lr.fit(trainingData)\n",
    "m_dt = pipeline_dt.fit(trainingData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3c527de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+------------------+\n",
      "|        features|label|        prediction|\n",
      "+----------------+-----+------------------+\n",
      "|  [8.4,27.2,2.1]|  5.7| 7.973557851423301|\n",
      "|   [8.6,2.1,1.0]|  4.8| 3.561616044078974|\n",
      "|[17.2,45.9,69.3]|  9.3|11.711653904464114|\n",
      "|[18.7,12.1,23.4]|  6.7| 5.818699366218825|\n",
      "|[19.4,16.0,22.3]|  6.6|6.5393465940091815|\n",
      "+----------------+-----+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------------+-----+------------------+\n",
      "|        features|label|        prediction|\n",
      "+----------------+-----+------------------+\n",
      "|  [8.4,27.2,2.1]|  5.7|1.6000000000000005|\n",
      "|   [8.6,2.1,1.0]|  4.8|               3.2|\n",
      "|[17.2,45.9,69.3]|  9.3| 8.633333333333333|\n",
      "|[18.7,12.1,23.4]|  6.7| 7.266666666666668|\n",
      "|[19.4,16.0,22.3]|  6.6| 7.266666666666668|\n",
      "+----------------+-----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make Predictions\n",
    "predictions_lr = m_lr.transform(testData)\n",
    "predictions_dt = m_dt.transform(testData)\n",
    "\n",
    "predictions_lr.select(\"features\", \"label\", \"prediction\").show(5)\n",
    "predictions_dt.select(\"features\", \"label\", \"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a6f26cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) of Linear Regression on test data = 1.5890878967986943\n",
      "Root Mean Squared Error (RMSE) of Decision Tree on test data = 1.592461187516625\n"
     ]
    }
   ],
   "source": [
    "# Evaluatin\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\"\n",
    ")\n",
    "\n",
    "rmse_lr = evaluator.evaluate(predictions_lr)\n",
    "print(f\"Root Mean Squared Error (RMSE) of Linear Regression on test data = {rmse_lr}\")\n",
    "\n",
    "rmse_dt = evaluator.evaluate(predictions_dt)\n",
    "print(f\"Root Mean Squared Error (RMSE) of Decision Tree on test data = {rmse_dt}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "02f6df1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score of Linear Regression on test data = 0.8964471118845287\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "y_true = predictions_lr.select(\"label\").toPandas()\n",
    "y_pred = predictions_lr.select(\"prediction\").toPandas()\n",
    "\n",
    "r2_score = sklearn.metrics.r2_score(y_true, y_pred)\n",
    "print(f\"R2 Score of Linear Regression on test data = {r2_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ca569a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(3, {0: 0.6226, 1: 0.3502, 2: 0.0271})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_dt.stages[1].featureImportances"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
